{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 跟 prompt相关"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# An example prompt with no input variables\n",
    "no_input_prompt = PromptTemplate(input_variables=[], template=\"Tell me a joke.\")\n",
    "no_input_prompt.format()\n",
    "# -> \"Tell me a joke.\"\n",
    "\n",
    "# An example prompt with one input variable\n",
    "one_input_prompt = PromptTemplate(input_variables=[\"adjective\"], template=\"Tell me a {adjective} joke.\")\n",
    "one_input_prompt.format(adjective=\"funny\")\n",
    "print(type(one_input_prompt))\n",
    "# -> \"Tell me a funny joke.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 跟chat相关"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import promptlayer\n",
    "import os\n",
    "\n",
    "openai = promptlayer.openai\n",
    "openai.organization = os.getenv(\"OPENAI_ORGANIZATION\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "promptlayer.api_key = os.environ.get(\"PROMPTLAYER_API_KEY\")\n",
    "\n",
    "# read system message from txt file System Message Generator.txt\n",
    "model_name = \"gpt-4\"\n",
    "system_message = \"\"\n",
    "# with open(\"System Message Generator.txt\", \"r\") as f:\n",
    "#     system_message = f.read()\n",
    "\n",
    "\n",
    "import os\n",
    "from langchain.chat_models import PromptLayerChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "chat = PromptLayerChatOpenAI(pl_tags=[\"langchain\", model_name], model_name=model_name)\n",
    "messages = [SystemMessage(content=system_message)]\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
